{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Machine learning algorithms can outperform some radiologists in cancer diagnosis, but can they also have good reasonings to support their classifications? The main goal of our project is to increase the 'explainability' of the models we explored. Namely, our algorithms do not only identify whether there is abnormality in a given image, but also localize where the problem is when they find lesions in the image.\n",
    "\n",
    "To achieve this goal, we mainly experiment with ResNet and U-Net. ResNet allows us to train deep CNN models relatively efficiently. It gives out binary classification prediction (normal/abnormal) for each given image. To visualize where the model 'thinks' the trouble regions are in the images predicted to be abnormal, we generate saliency maps from ResNet. On the other hand, U-Net's prediction output consists of class labels assigned to each pixel in the given image, so it directly indicates the location of nodules. \n",
    "\n",
    "We also think up two ways to combine the advantages of the two models. One is to restructure U-Net by adding shortcut connections to the neural network so it can be trained more efficiently with a deeper structure, which may lead to better performance in limited time. Another is to stack ResNet and U-Net to improve the overall diagnosis accuracy of the models. \n",
    "\n",
    "All of the models are tested on the CBIS-DDSM data set (Curated Breast Imaging Subset of DDSM) ([4]), which is the updated version of DDSM (Digital Database for Screening Mammography). The models are evaluated by 3 metrics, diagnosis accuracy, pixel accuracy and intersecion over union ratio. The first metric measures whether the model gives right binary classification prediction (normal/abnormal) for an image, while the other two metrics measure whether the model does well on tumor localization.\n",
    "\n",
    "Our final delivery of the project is an online prediction function, which gives binary classification prediction and heatmap with tumor localization for each given image.\n",
    "\n",
    "## Literature Review\n",
    "\n",
    "Artificial Neural Networks are now broadly applied in the study and modeling of cancers. They are used for susceptibility analysis and disease diagnosis. Their ability to model nonlinear relationships allow them to better predict treatment outcomes and therefore improve and even design individualized treatment plans. Experiments show that they can even outperform experienced experts (Steiner, 2017).\n",
    "\n",
    "The lack of training data is a common problem in the machine learning study of Mammography. To overcome this problem, ResNet performs data augmentations such as shift, rotation, grey value variation, and random elastic deformation (He, Zhang, Ren & Sun, 2016). Class-conditional generative adversarial networks (GANs) are also used to synthesize healthy screening and artificial lesion signals to produce new training samples (Wu, Wu, Cox & Lotter, 2017).\n",
    "\n",
    "For cancer diagnosis, in addition to simple classification, we also care for the location of the cancer cells. This is the motivation for U-Net as an image segmentation algorithm proposed by Ronneberger, Fischer and Brox (2017). A U-Net consists of a series of pooling layers and a series of upsampling layers, so the neural network as a whole has a symmetric U-shape. It uses the upsampling layers to increase resolution and therefore accuracy of the output, and it combines the upsampling section with feature maps from the contracting section in order to localize the output within context.\n",
    "\n",
    "After we construct these deep convolutional networks, experiments show that they are harder to train -- with the same number of iterations, they have higher training error than shallower networks. Thus, deep residual learning is proposed to solve this degradation problem (He, Zhang, Ren & Sun, 2016). It adds shortcut connections to make certain layers explicitly approximate residual functions. This architecture brings two benefits: first, the network is easier to optimize (achieve low training error faster); second, it has lower complexity (no extra parameter or complexity from identity shortcut connections)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We use data from the CBIS-DDSM data set. We use this data set because it includes cleaned data from DDSM and all the images are reformatted to dicom files. The whole data set covers two kinds of tumors, mass and calcification. We only use data of mass cases as we think there may be distinctions in these two categories of problems, which means they need to be identified by two models separately. \n",
    "\n",
    "The original data set is already divided into training data and testing data, which are picked by the researchers meticulously to make sure that the two data sets are balanced with the same proportion of classification and situation. The training data set contains 1318 cases while the testing data set contains 378 cases. \n",
    "\n",
    "For each case, a dicom file of the X-ray image and a dicom file of regions of interest segmentation with the same shape are provided. The regions of interest segmentation files are masks with 0 (normal) and 1 (abnormal) annotated pixel by pixel. The images are often arrays with both width and height larger than 4000 and shapes of the images are varied, so we crop the images into $256*256$ patches. To limit the size of the data set and avoid meaningless cropped images (all dark or contains other parts of body), we keep all cropped images with 1 in the regions of interest segmentation files (which means there is abnormality in these images) and randomly pick cropped images with no trouble regions, which results in 19702 train images and 5835 test images. The proportion of abnormal data in both data sets is 0.3.\n",
    "\n",
    "The codes for data cleaning and data preprocessing are presented as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "from pathlib import *\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mass_train_description = pd.read_csv(\"mass_case_description_train_set.csv\")\n",
    "\n",
    "# Get the path of the image and store the array into the dictionary whose key is patient id, side and view\n",
    "\n",
    "file_dic = {}\n",
    "for i in range(len(mass_train_description)):\n",
    "    patient_id = mass_train_description['patient_id'].iloc[i]\n",
    "    side = mass_train_description['left or right breast'].iloc[i]\n",
    "    view = mass_train_description['image view'].iloc[i]\n",
    "    pid = patient_id + side + view\n",
    "\n",
    "    p = Path(\"Mass_Training_image/\"+(mass_train_description['image file path'].iloc[i]).split('/')[0])\n",
    "    lst = list(p.glob('**/*.dcm'))\n",
    "    dcm = pydicom.read_file(str(lst[0]))\n",
    "    file = \"Mass_Training/\" + pid + \"train_X.npy\"\n",
    "    np.save(file, dcm.pixel_array)\n",
    "    file_dic[pid] = [file]\n",
    "    \n",
    "    df = mass_train_description[\n",
    "        (mass_train_description['patient_id']==patient_id) & (mass_train_description['left or right breast']==side) & (mass_train_description['image view']==view)]\n",
    "\n",
    "    # The same image may have more than 1 overlay files, so we have to add them together to obtain the final file\n",
    "    label = np.zeros(dcm.pixel_array.shape)\n",
    "    for j in range(len(df)):\n",
    "        p = Path(\"Mass_Training_label/\"+(df['ROI mask file path'].iloc[j]).split('/')[0])\n",
    "        lst = list(p.glob('**/*.dcm'))\n",
    "        for pic in lst:\n",
    "            dcm = pydicom.read_file(str(pic))\n",
    "            if (dcm.pixel_array.shape) == label.shape:\n",
    "                label = label + dcm.pixel_array\n",
    "    file = \"Mass_Training/\" + pid + \"train_y.npy\"\n",
    "    np.save(file, label)\n",
    "    file_dic[pid].append(file)\n",
    "\n",
    "mass_training_path = pd.DataFrame(file_dic)\n",
    "mass_training_path = mass_training_path.transpose()\n",
    "mass_training_path.columns = ['train_X', 'train_y']\n",
    "mass_training_path.to_csv(\"mass_training_path.csv\")\n",
    "\n",
    "mass_test_description = pd.read_csv(\"mass_case_description_test_set.csv\")\n",
    "\n",
    "## Get the path of the image and store the array into the dictionary whose key is patient id, side and view\n",
    "\n",
    "file_dic = {}\n",
    "for i in range(len(mass_test_description)):\n",
    "    patient_id = mass_test_description['patient_id'].iloc[i]\n",
    "    side = mass_test_description['left or right breast'].iloc[i]\n",
    "    view = mass_test_description['image view'].iloc[i]\n",
    "    pid = patient_id + side + view\n",
    "\n",
    "    p = Path(\"Mass_Testing_image/\"+(mass_test_description['image file path'].iloc[i]).split('/')[0])\n",
    "    lst = list(p.glob('**/*.dcm'))\n",
    "    dcm = pydicom.read_file(str(lst[0]))\n",
    "    file = \"Mass_Testing/\" + pid + \"test_X.npy\"\n",
    "    np.save(file, dcm.pixel_array)\n",
    "    file_dic[pid] = [file]\n",
    "    \n",
    "    df = mass_test_description[\n",
    "        (mass_test_description['patient_id']==patient_id) & (mass_test_description['left or right breast']==side) & (mass_test_description['image view']==view)]\n",
    "\n",
    "    ## The same image may have more than 1 overlay files, so we have to add them together to obtain the final file\n",
    "    label = np.zeros(dcm.pixel_array.shape)\n",
    "    for j in range(len(df)):\n",
    "        p = Path(\"Mass_Testing_label/\"+(df['ROI mask file path'].iloc[j]).split('/')[0])\n",
    "        lst = list(p.glob('**/*.dcm'))\n",
    "        for pic in lst:\n",
    "            dcm = pydicom.read_file(str(pic))\n",
    "            if (dcm.pixel_array.shape) == label.shape:\n",
    "                label = label + dcm.pixel_array\n",
    "    file = \"Mass_Testing/\" + pid + \"test_y.npy\"\n",
    "    np.save(file, label)\n",
    "    file_dic[pid].append(file)\n",
    "\n",
    "mass_testing_path = pd.DataFrame(file_dic)\n",
    "mass_testing_path = mass_testing_path.transpose()\n",
    "mass_testing_path.columns = ['test_X', 'test_y']\n",
    "mass_testing_path.to_csv(\"mass_testing_path.csv\")\n",
    "\n",
    "mass_training = pd.read_csv(\"mass_training_path.csv\")\n",
    "x_shape = 256\n",
    "y_shape = 256\n",
    "p = 0.1\n",
    "\n",
    "k = 1\n",
    "file_dic = {}\n",
    "for num in range(len(mass_training)):\n",
    "    p_X =Path(mass_training['train_X'].iloc[num])\n",
    "    p_y = Path(mass_training['train_y'].iloc[num])\n",
    "    train_X = np.load(p_X)\n",
    "    train_y = np.load(p_y)\n",
    "    x_dim = int(test_X.shape[0] / x_shape) + 1\n",
    "    y_dim = int(test_X.shape[1] / y_shape) + 1\n",
    "\n",
    "    # crop the images into 256*256 patches\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            s = train_X[i*x_shape:(i+1)*x_shape,j*y_shape:(j+1)*y_shape]\n",
    "            l = train_y[i*x_shape:(i+1)*x_shape,j*y_shape:(j+1)*y_shape]\n",
    "            if(s.shape == (x_shape,y_shape)):\n",
    "                if (sum(sum(l)) > 0):\n",
    "                    path_X = Path(\"Train_X/\"+str(k)+(mass_training['train_X'].iloc[num]).split('/')[1])\n",
    "                    np.save(path_X, s)\n",
    "                    path_y = Path(\"Train_y/\"+str(k)+(mass_training['train_X'].iloc[num]).split('/')[1])\n",
    "                    np.save(path_y, l)\n",
    "                    file_dic[k] = [path_X, path_y]\n",
    "                    k = k + 1\n",
    "                # randomly choose images without abnormality\n",
    "                elif (random.random() < p):\n",
    "                    # filter all dark images and meaningless images\n",
    "                    if (sum(sum(s)) > (x_shape*y_shape*110)) & (sum(sum(s)) < (x_shape*y_shape*140)):\n",
    "                        path_X = Path(\"Train_X/\"+str(k)+(mass_training['train_X'].iloc[num]).split('/')[1])\n",
    "                        np.save(path_X, s)\n",
    "                        path_y = Path(\"Train_y/\"+str(k)+(mass_testing['train_X'].iloc[num]).split('/')[1])\n",
    "                        np.save(path_y, l)\n",
    "                        file_dic[k] = [path_X, path_y]\n",
    "                        k = k + 1\n",
    "                        \n",
    "mass_training_path = pd.DataFrame(file_dic)\n",
    "mass_training_path = mass_training_path.transpose()\n",
    "mass_training_path.columns = ['train_X', 'train_y']\n",
    "mass_training_path.to_csv(\"mass_training_path.csv\")\n",
    "\n",
    "mass_testing = pd.read_csv(\"mass_testing_path.csv\")\n",
    "x_shape = 256\n",
    "y_shape = 256\n",
    "p = 0.1\n",
    "\n",
    "k = 1\n",
    "file_dic = {}\n",
    "for num in range(len(mass_testing)):\n",
    "    p_X =Path(mass_testing['test_X'].iloc[num])\n",
    "    p_y = Path(mass_testing['test_y'].iloc[num])\n",
    "    test_X = np.load(p_X)\n",
    "    test_y = np.load(p_y)\n",
    "    x_dim = int(test_X.shape[0] / x_shape) + 1\n",
    "    y_dim = int(test_X.shape[1] / y_shape) + 1\n",
    "\n",
    "    # crop the images into 256*256 patches\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            s = test_X[i*x_shape:(i+1)*x_shape,j*y_shape:(j+1)*y_shape]\n",
    "            l = test_y[i*x_shape:(i+1)*x_shape,j*y_shape:(j+1)*y_shape]\n",
    "            if(s.shape == (x_shape,y_shape)):\n",
    "                if (sum(sum(l)) > 0):\n",
    "                    path_X = Path(\"Test_X/\"+str(k)+(mass_testing['test_X'].iloc[num]).split('/')[1])\n",
    "                    np.save(path_X, s)\n",
    "                    path_y = Path(\"Test_y/\"+str(k)+(mass_testing['test_X'].iloc[num]).split('/')[1])\n",
    "                    np.save(path_y, l)\n",
    "                    file_dic[k] = [path_X, path_y]\n",
    "                    k = k + 1\n",
    "                # randomly choose images without abnormality\n",
    "                elif (random.random() < p):\n",
    "                    # filter all dark images and meaningless images\n",
    "                    if (sum(sum(s)) > (x_shape*y_shape*110)) & (sum(sum(s)) < (x_shape*y_shape*140)):\n",
    "                        path_X = Path(\"Test_X/\"+str(k)+(mass_testing['test_X'].iloc[num]).split('/')[1])\n",
    "                        np.save(path_X, s)\n",
    "                        path_y = Path(\"Test_y/\"+str(k)+(mass_testing['test_X'].iloc[num]).split('/')[1])\n",
    "                        np.save(path_y, l)\n",
    "                        file_dic[k] = [path_X, path_y]\n",
    "                        k = k + 1\n",
    "                        \n",
    "mass_testing_path = pd.DataFrame(file_dic)\n",
    "mass_testing_path = mass_testing_path.transpose()\n",
    "mass_testing_path.columns = ['test_X', 'test_y']\n",
    "mass_testing_path.to_csv(\"mass_testing_path.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[1] Steiner. “Solving Cancer: The Use of Artificial Neural Networks in Cancer Diagnosis and Treatment.” Journal of Young Investigators, 33(5). 2017.\n",
    "\n",
    "[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. “Deep Residual Learning for Image Recognition.” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, doi:10.1109/cvpr.2016.90.\n",
    "\n",
    "[3] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. “U-Net Convolutional Networks for Biomedical Image Segmentation.” Informatik Aktuell Bildverarbeitung Für Die Medizin 2017, 2017, pp. 3–3., doi:10.1007/978-3-662-54345-0_3.\n",
    "\n",
    "[4] https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM\n",
    "\n",
    "[5] Bo Dai, Sanja Fidler, Raquel Urtasun, Dahua Lin. “Towards Diverse and Natural Image Descriptions via a Conditional GAN.” 2017 IEEE International Conference on Computer Vision (ICCV), 2017, doi:10.1109/iccv.2017.323.\n",
    "\n",
    "[6] Wu, Eric, Kevin Wu, David Cox, and William Lotter. \"Conditional Infilling GANs for Data Augmentation in Mammogram Classification.\" Image Analysis for Moving Organ, Breast, and Thoracic Images Lecture Notes in Computer Science, 2018, 98-106. doi:10.1007/978-3-030-00946-5_11."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
